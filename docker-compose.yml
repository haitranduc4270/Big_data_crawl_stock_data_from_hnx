version: "3"

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    ports:
      - 9864:9864
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    depends_on:
      - namenode

  # pyspark-prj:
  #   image: jupyter/pyspark-notebook
  #   container_name: notebook
  #   ports:
  #     - "8888:8888"
  #   volumes:
  #     - ../big_data_20221/:/home/jovyan/work/

  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    depends_on:
      - namenode
      - datanode
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000

  spark-worker:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.1
    container_name: elasticsearch
    volumes:
      - esdata:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      - xpack.security.enabled=false
      - "discovery.type=single-node"
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G

  kibana:
    image: docker.elastic.co/kibana/kibana:7.15.1
    container_name: kibana
    ports:
      - 5601:5601
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
    depends_on:
      - elasticsearch

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    expose:
      - "2181"
    ports:
      - 2181:2181

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    expose:
      - "9092"
    ports:
      - 9092:9092
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ADVERTISED_LISTENERS: INSIDE://:9092,OUTSIDE://localhost:19092
      KAFKA_LISTENERS: INSIDE://:9092,OUTSIDE://0.0.0.0:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
    depends_on:
      - zookeeper

  pyspark_application:
    image: myracoon/racoon_pyspark:mongo
    container_name: pyspark_application
    restart: always
    depends_on:
      - namenode
      - datanode
      - spark-master
      - spark-worker
      - elasticsearch
      - kibana
      - zookeeper
      - kafka
    volumes:
      - ../big_data_20221/pyspark_application/:/app

  stock_iboard_crawler:
    image: myracoon/racoon_pyspark:mongo
    container_name: stock_iboard_crawler
    restart: always
    depends_on:
      - namenode
      - datanode
      - spark-master
      - spark-worker
      - elasticsearch
      - kibana
      - zookeeper
      - kafka
    volumes:
      - ../big_data_20221/stock_iboard_crawler/:/app

  articles_crawler:
    image: myracoon/racoon_node:latest
    container_name: articles_crawler
    restart: always
    depends_on:
      - namenode
      - datanode
      - spark-master
      - spark-worker
      - elasticsearch
      - kibana
      - zookeeper
      - kafka
    volumes:
      - ../big_data_20221/articles_crawler/:/app

  articles_server:
    image: myracoon/racoon_node:latest
    container_name: articles_server
    restart: always
    expose:
      - "3000"
    ports:
      - 3000:3000
    volumes:
      - ../big_data_20221/articles_server/:/app

volumes:
  hadoop_namenode:
  hadoop_datanode:
  esdata:
